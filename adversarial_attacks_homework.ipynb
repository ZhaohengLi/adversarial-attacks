{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adversarial Attack\n",
    "\n",
    "We assume that you have read the [Adversarial Attacks Tutorial](./adversarial_attacks_tutorial.ipynb) carefully and run that notebook from scratch. \n",
    "\n",
    "In this notebook, you are required to process adversarial attacks for a small subset of [ImageNet Dataset](http://www.image-net.org/). We prepared 100 images from different categories (in `./input_dir/`), and the labels are encoded in `./input_dir/clean_image.list`.\n",
    "\n",
    "For evaluation, each adversarial image generated by the attack model will be fed to an evaluation model, and we will calculate the successful rate of adversarial attacks. **The adversarial images that can fool the evaluation model and also the perturbations are less than *Max_Distance* will be considered as a success**, where the perturbations are measured by the L2 distance between the adversarial image and original image.\n",
    "\n",
    "There are three tasks:\n",
    "- **White-box attack**: the adversarial examples are crafted for the pretrained **MobileNetV2** model, and evaluated on the same **MobileNetV2** model.\n",
    "- **Black-box attack**: the adversarial examples are crafted for the pretrained **MobileNetV2** model, but evaluated on the **MobileNet** model, which is different from MobileNetV2.\n",
    "- **Black-box attack (after submission)**: you are required to submit the generated adversarial examples at last, and we will evaluate your adversarial examples on another model, which is invisible for you.\n",
    "\n",
    "### Goal\n",
    "\n",
    "We provide a simple FGSM example here, and you are required to implement your own attack methods to **achieve the attack successful rate as high as possible** (for all three tasks).\n",
    "\n",
    "At last, you are required to submit this jupyter notebook and the generated adversarial images.\n",
    "The final grade will be scored according to the **white-box successful rate**, **black-box successful rate**, **white-box (after submission) successful rate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install cython\n",
    "# ! pip3 install tensornets\n",
    "# ! pip3 install numpy==1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "from utils import *\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images\n",
    "We provided 100 images from different categories in `./input_dir/`, and the labels are encoded in `./input_dir/clean_image.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "with open('./input_dir/clean_image.list', 'r') as f:\n",
    "    img_lines = f.readlines()\n",
    "    for img_line in img_lines:\n",
    "        imgname, label = img_line.strip('\\n').split(' ')\n",
    "        images.append((imgname, int(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "Each input image must be preprocessed before fed into the models, such as normalization(subtracting the mean and then dividing by the standard deviation). In addition, each generated adversarial image must be reversely processed.\n",
    "Note that different pretrained models in Tensorflow require different preprocessing.\n",
    "We provided several `preprocess` and `reverse_preprocess` function for different deep networks in `./utils.py`.\n",
    "\n",
    "By default, the two functions are designed for mobilenet models.\n",
    "```python\n",
    "preprocess(image, model=\"mobilenet\")\n",
    "reverse_preprocess(image, model=\"mobilenet\")\n",
    "```\n",
    "\n",
    "If you want to change to other models, see `./utils.py` for more details.\n",
    "\n",
    "We have downloaded several popular pretrained models, you can adopt these models as the attacked model.\n",
    "## Pretrained Models in tensornets (nets)\n",
    "    'DenseNet121', 'DenseNet169', 'DenseNet201', \n",
    "    'Inception1', 'Inception2', 'Inception3', 'Inception4', 'InceptionResNet2',\n",
    "    'MobileNet25', 'MobileNet50', 'MobileNet75', MobileNet100', \n",
    "    'MobileNet35v2', 'MobileNet50v2', 'MobileNet75v2', 'MobileNet100v2', 'MobileNet130v2', 'MobileNet140v2', \n",
    "    'NASNetAlarge', 'NASNetAmobile', 'PNASNetlarge',\n",
    "    'ResNet50', 'ResNet101', 'ResNet152', 'ResNet50v2', 'ResNet101v2', 'ResNet152v2', 'ResNet200v2', \n",
    "    'ResNeXt50c32', 'ResNeXt101c32', 'ResNeXt101c64', 'WideResNet50',\n",
    "    'VGG16', 'VGG19', \n",
    "    'SqueezeNet'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Attack Method\n",
    "\n",
    "### TODO: implement your own attack methods.\n",
    "\n",
    "###  Tips:\n",
    "- We provide the simple FGSM attack method as an example here. You can try other attack methods (learned in this course), such as the iterative methods.\n",
    "- For black-box attack, we adopt the `MobileNetV2` as the attacked model, and the generated adversarial images may failed in `MobileNet` (which indicates poor transferability). You can try other attacked models (except `MobileNet`) or model ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attack:\n",
    "    def __init__(self, input_image):\n",
    "        self.input_image = input_image\n",
    "        \n",
    "        # loss function\n",
    "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        # TODO: you may change your target model.\n",
    "        # load the model which will be attacked\n",
    "        self.attacked_model = nets.MobileNet50v2(input_image, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def generate_adversarial_example(self, input_label):\n",
    "#         input_image = self.input_image\n",
    "#         prediction = self.attacked_model\n",
    "#         loss = self.loss_object(input_label, prediction)\n",
    "#\n",
    "#         # TODO: implement your own attack methods.\n",
    "#         # Get the gradients of the loss w.r.t to the input image.\n",
    "#         gradient = tf.gradients(loss, input_image)\n",
    "        \n",
    "#         # Get the sign of the gradients to create the perturbation (FGSM)\n",
    "#         signed_grad = tf.sign(gradient)[0]\n",
    "#         # Epsilon in FGSM, you can try another value.\n",
    "#         eps = 0.05\n",
    "#         adv_image = input_image + eps * signed_grad\n",
    "        \n",
    "#         # Clip the generated image between -1 and 1. Note that different pretrained models require different ranges.\n",
    "#         adv_image = tf.clip_by_value(adv_image, -1, 1)\n",
    "        \n",
    "#         # END TODO\n",
    "        input_image = self.input_image\n",
    "        \n",
    "        adv_image = input_image\n",
    "        g = 0.0\n",
    "        u = 1.0\n",
    "        eps = 0.001\n",
    "        \n",
    "        for t in range(1,16):\n",
    "            prediction = nets.MobileNet50v2(adv_image, reuse=tf.AUTO_REUSE)\n",
    "            loss = self.loss_object(input_label, prediction)\n",
    "            gradient = tf.gradients(loss, adv_image)\n",
    "            g = u*g + gradient[0]/tf.norm(gradient,ord=1)\n",
    "            adv_image = tf.clip_by_value(adv_image+eps/t*tf.sign(g)[0], -1, 1)\n",
    "            \n",
    "        return adv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Define the evaluation functions for both white-box and black-box attack.\n",
    "**You are not allowed to modify these codes.**\n",
    "\n",
    "- For white-box attack, the adversarial images are evaluated on the `MobileNetv2` model.\n",
    "- For black-box attack, the adversarial images are evaluated on the `MobileNet` model. Therefore, you can not use the same `MobileNet` model as the attacked model.\n",
    "\n",
    "The `Max_Distance` equals to 5.0 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Distance = 5.0\n",
    "\n",
    "class WhiteBox_Evaluation:\n",
    "    def __init__(self, adv_image):\n",
    "        self.adv_image = adv_image\n",
    "        self.eval_model = nets.MobileNet50v2(adv_image, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def get_adv_label(self):\n",
    "        adv_probs  = self.eval_model\n",
    "        adv_label = tf.argmax(adv_probs,1)\n",
    "        return adv_label\n",
    "    \n",
    "class BlackBox_Evaluation:\n",
    "    def __init__(self, adv_image):\n",
    "        self.adv_image = adv_image\n",
    "        self.eval_model = nets.MobileNet50(adv_image, reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def get_adv_label(self):\n",
    "        adv_probs  = self.eval_model\n",
    "        adv_label = tf.argmax(adv_probs,1)\n",
    "        return adv_label\n",
    "    \n",
    "# init the attacker\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# load and preprocess image\n",
    "input_path = tf.placeholder(dtype=tf.string)\n",
    "input_label = tf.placeholder(shape=None, dtype=tf.int32)\n",
    "image_raw = tf.io.read_file(input_path)\n",
    "image = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "image = image[None, ...]\n",
    "\n",
    "input_image = preprocess(image)\n",
    "attacker = Attack(input_image)\n",
    "\n",
    "# generate adversarial example\n",
    "adv_image_t = attacker.generate_adversarial_example(input_label)\n",
    "eval_model_white = WhiteBox_Evaluation(adv_image_t)\n",
    "eval_model_black = BlackBox_Evaluation(adv_image_t)\n",
    "\n",
    "# measured by L2 distance\n",
    "distance_t = tf.math.reduce_euclidean_norm(input_image - adv_image_t)\n",
    "\n",
    "adv_label_white_t = eval_model_white.get_adv_label()\n",
    "adv_label_black_t = eval_model_black.get_adv_label()\n",
    "\n",
    "saved_image_t = reverse_preprocess(adv_image_t)[0]\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "_ = sess.run([attacker.attacked_model.pretrained(), eval_model_white.eval_model.pretrained(), eval_model_black.eval_model.pretrained()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White-Box Attack Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02708093.JPEG: clean_label=409 adv_label=592 distance=0.97\n",
      "n03000134.JPEG: clean_label=489 adv_label=352 distance=1.15\n",
      "n03384352.JPEG: clean_label=561 adv_label=495 distance=1.07\n",
      "n03777754.JPEG: clean_label=662 adv_label=882 distance=1.09\n",
      "n03721384.JPEG: clean_label=642 adv_label=696 distance=1.11\n",
      "n03424325.JPEG: clean_label=570 adv_label=691 distance=1.09\n",
      "n03673027.JPEG: clean_label=628 adv_label=833 distance=1.09\n",
      "n02229544.JPEG: clean_label=312 adv_label=456 distance=1.07\n",
      "n07695742.JPEG: clean_label=932 adv_label=925 distance=1.11\n",
      "n02018207.JPEG: clean_label=137 adv_label=137 distance=1.13\n",
      "n02107908.JPEG: clean_label=240 adv_label=178 distance=1.07\n",
      "n04026417.JPEG: clean_label=748 adv_label=643 distance=1.11\n",
      "n02444819.JPEG: clean_label=360 adv_label=150 distance=1.13\n",
      "n02259212.JPEG: clean_label=317 adv_label=462 distance=1.10\n",
      "n02480495.JPEG: clean_label=365 adv_label=341 distance=1.11\n",
      "n02095889.JPEG: clean_label=190 adv_label=190 distance=1.13\n",
      "n03216828.JPEG: clean_label=536 adv_label=536 distance=1.12\n",
      "n01817953.JPEG: clean_label= 87 adv_label= 34 distance=1.09\n",
      "n02422106.JPEG: clean_label=351 adv_label=350 distance=1.11\n",
      "n04376876.JPEG: clean_label=845 adv_label=405 distance=0.90\n",
      "n02099267.JPEG: clean_label=205 adv_label=246 distance=1.10\n",
      "n04398044.JPEG: clean_label=849 adv_label=505 distance=1.09\n",
      "n04023962.JPEG: clean_label=747 adv_label=982 distance=1.10\n",
      "n02093256.JPEG: clean_label=179 adv_label=252 distance=1.05\n",
      "n03109150.JPEG: clean_label=512 adv_label=543 distance=0.99\n",
      "n12267677.JPEG: clean_label=988 adv_label=988 distance=1.12\n",
      "n02667093.JPEG: clean_label=399 adv_label=614 distance=1.14\n",
      "n03956157.JPEG: clean_label=727 adv_label=344 distance=1.00\n",
      "n02033041.JPEG: clean_label=142 adv_label=141 distance=1.10\n",
      "n02071294.JPEG: clean_label=148 adv_label=148 distance=1.13\n",
      "n02704792.JPEG: clean_label=408 adv_label=975 distance=1.12\n",
      "n02013706.JPEG: clean_label=135 adv_label=135 distance=1.16\n",
      "n02177972.JPEG: clean_label=307 adv_label= 73 distance=1.07\n",
      "n03042490.JPEG: clean_label=500 adv_label= 20 distance=1.13\n",
      "n01443537.JPEG: clean_label=  1 adv_label=973 distance=1.11\n",
      "n02093647.JPEG: clean_label=181 adv_label=279 distance=1.07\n",
      "n04536866.JPEG: clean_label=889 adv_label=436 distance=1.06\n",
      "n07717556.JPEG: clean_label=942 adv_label=925 distance=1.06\n",
      "n03016953.JPEG: clean_label=493 adv_label=493 distance=1.13\n",
      "n04493381.JPEG: clean_label=876 adv_label=394 distance=1.10\n",
      "n04590129.JPEG: clean_label=905 adv_label=799 distance=1.10\n",
      "n02769748.JPEG: clean_label=414 adv_label=414 distance=1.13\n",
      "n03063599.JPEG: clean_label=504 adv_label=647 distance=1.12\n",
      "n04065272.JPEG: clean_label=757 adv_label=847 distance=1.10\n",
      "n02012849.JPEG: clean_label=134 adv_label= 99 distance=1.13\n",
      "n02655020.JPEG: clean_label=397 adv_label= 58 distance=1.11\n",
      "n04548280.JPEG: clean_label=892 adv_label=855 distance=1.08\n",
      "n02129604.JPEG: clean_label=292 adv_label=568 distance=1.10\n",
      "n03393912.JPEG: clean_label=565 adv_label=771 distance=1.13\n",
      "n02110341.JPEG: clean_label=251 adv_label=683 distance=1.11\n",
      "n02791270.JPEG: clean_label=424 adv_label=739 distance=1.10\n",
      "n04251144.JPEG: clean_label=801 adv_label=445 distance=1.12\n",
      "n02443114.JPEG: clean_label=358 adv_label=336 distance=1.12\n",
      "n12144580.JPEG: clean_label=987 adv_label=952 distance=1.05\n",
      "n02966687.JPEG: clean_label=477 adv_label=800 distance=1.14\n",
      "n03584254.JPEG: clean_label=605 adv_label=435 distance=1.10\n",
      "n02110185.JPEG: clean_label=250 adv_label=200 distance=1.12\n",
      "n02790996.JPEG: clean_label=422 adv_label=851 distance=1.11\n",
      "n02815834.JPEG: clean_label=438 adv_label=438 distance=1.06\n",
      "n07831146.JPEG: clean_label=959 adv_label=964 distance=1.12\n",
      "n04311174.JPEG: clean_label=822 adv_label=666 distance=1.06\n",
      "n01955084.JPEG: clean_label=116 adv_label=126 distance=1.10\n",
      "n09332890.JPEG: clean_label=975 adv_label=450 distance=1.11\n",
      "n03197337.JPEG: clean_label=531 adv_label=464 distance=1.07\n",
      "n03467068.JPEG: clean_label=583 adv_label=760 distance=1.14\n",
      "n03201208.JPEG: clean_label=532 adv_label=765 distance=1.11\n",
      "n03485407.JPEG: clean_label=590 adv_label=590 distance=1.01\n",
      "n03873416.JPEG: clean_label=693 adv_label= 80 distance=1.10\n",
      "n03131574.JPEG: clean_label=520 adv_label=516 distance=1.12\n",
      "n07754684.JPEG: clean_label=955 adv_label=996 distance=1.14\n",
      "n02086240.JPEG: clean_label=155 adv_label=155 distance=1.13\n",
      "n07836838.JPEG: clean_label=960 adv_label=941 distance=1.11\n",
      "n03160309.JPEG: clean_label=525 adv_label=672 distance=1.08\n",
      "n09399592.JPEG: clean_label=976 adv_label=978 distance=1.06\n",
      "n02777292.JPEG: clean_label=416 adv_label=639 distance=1.09\n",
      "n02326432.JPEG: clean_label=331 adv_label=186 distance=1.09\n",
      "n01664065.JPEG: clean_label= 33 adv_label= 32 distance=1.11\n",
      "n01537544.JPEG: clean_label= 14 adv_label=442 distance=1.10\n",
      "n07583066.JPEG: clean_label=924 adv_label=936 distance=1.14\n",
      "n02814860.JPEG: clean_label=437 adv_label=745 distance=0.94\n",
      "n04153751.JPEG: clean_label=783 adv_label=783 distance=1.01\n",
      "n03379051.JPEG: clean_label=560 adv_label=560 distance=1.16\n",
      "n04597913.JPEG: clean_label=910 adv_label=477 distance=1.16\n",
      "n03977966.JPEG: clean_label=734 adv_label=569 distance=1.13\n",
      "n04606251.JPEG: clean_label=913 adv_label=976 distance=1.08\n",
      "n01773157.JPEG: clean_label= 72 adv_label= 72 distance=1.06\n",
      "n01688243.JPEG: clean_label= 43 adv_label= 42 distance=1.12\n",
      "n01829413.JPEG: clean_label= 93 adv_label= 93 distance=1.14\n",
      "n04525038.JPEG: clean_label=885 adv_label=957 distance=1.11\n",
      "n04049303.JPEG: clean_label=756 adv_label=756 distance=1.12\n",
      "n01877812.JPEG: clean_label=104 adv_label=272 distance=1.14\n",
      "n03394916.JPEG: clean_label=566 adv_label=451 distance=1.13\n",
      "n03794056.JPEG: clean_label=674 adv_label=512 distance=0.91\n",
      "n01530575.JPEG: clean_label= 10 adv_label= 13 distance=1.08\n",
      "n03207941.JPEG: clean_label=534 adv_label=807 distance=1.12\n",
      "n02109525.JPEG: clean_label=247 adv_label=219 distance=1.13\n",
      "n07697313.JPEG: clean_label=933 adv_label=923 distance=1.15\n",
      "n02489166.JPEG: clean_label=376 adv_label=379 distance=1.14\n",
      "n02794156.JPEG: clean_label=426 adv_label=884 distance=1.10\n",
      "n04131690.JPEG: clean_label=773 adv_label=503 distance=1.12\n",
      "\n",
      "White-box attack successful rate: 84%\n"
     ]
    }
   ],
   "source": [
    "success_cnt = 0\n",
    "\n",
    "for idx, (imgname, label) in enumerate(images):\n",
    "    imgpath = './input_dir/' + imgname\n",
    "    run_list = [adv_image_t, distance_t, adv_label_white_t, saved_image_t]\n",
    "    feed_dict = {input_path: imgpath, input_label: label}\n",
    "    \n",
    "    adv_image, distance, adv_label, saved_image = sess.run(run_list, feed_dict)\n",
    "    adv_label = adv_label[0]\n",
    "    \n",
    "    # if the adversarial image can successfully fool the attacked model, and the perturbations are less than Max_Distance\n",
    "    if distance <= Max_Distance:\n",
    "        success_cnt += 1 if adv_label != label else 0\n",
    "    \n",
    "    print('{}: clean_label={:3d} adv_label={:3d} distance={:.2f}'.format(imgname,label,adv_label,distance))\n",
    "    \n",
    "    # save the generated images to './output_dir'\n",
    "    saved_image = tf.image.encode_png(saved_image)\n",
    "    write_ops = tf.io.write_file('./output_dir/' + imgname, saved_image)\n",
    "    sess.run(write_ops)\n",
    "\n",
    "print()\n",
    "print('White-box attack successful rate: {}%'.format(success_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-Box Attack Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02708093.JPEG: clean_label=409 adv_label=409 distance=0.97\n",
      "n03000134.JPEG: clean_label=489 adv_label=489 distance=1.15\n",
      "n03384352.JPEG: clean_label=561 adv_label=561 distance=1.07\n",
      "n03777754.JPEG: clean_label=662 adv_label=662 distance=1.09\n",
      "n03721384.JPEG: clean_label=642 adv_label=642 distance=1.11\n",
      "n03424325.JPEG: clean_label=570 adv_label=570 distance=1.09\n",
      "n03673027.JPEG: clean_label=628 adv_label=628 distance=1.09\n",
      "n02229544.JPEG: clean_label=312 adv_label=872 distance=1.07\n",
      "n07695742.JPEG: clean_label=932 adv_label=925 distance=1.11\n",
      "n02018207.JPEG: clean_label=137 adv_label=137 distance=1.13\n",
      "n02107908.JPEG: clean_label=240 adv_label=241 distance=1.07\n",
      "n04026417.JPEG: clean_label=748 adv_label=748 distance=1.11\n",
      "n02444819.JPEG: clean_label=360 adv_label=360 distance=1.13\n",
      "n02259212.JPEG: clean_label=317 adv_label=317 distance=1.10\n",
      "n02480495.JPEG: clean_label=365 adv_label=365 distance=1.11\n",
      "n02095889.JPEG: clean_label=190 adv_label=190 distance=1.13\n",
      "n03216828.JPEG: clean_label=536 adv_label=536 distance=1.12\n",
      "n01817953.JPEG: clean_label= 87 adv_label= 87 distance=1.09\n",
      "n02422106.JPEG: clean_label=351 adv_label=351 distance=1.11\n",
      "n04376876.JPEG: clean_label=845 adv_label=845 distance=0.90\n",
      "n02099267.JPEG: clean_label=205 adv_label=205 distance=1.10\n",
      "n04398044.JPEG: clean_label=849 adv_label=849 distance=1.09\n",
      "n04023962.JPEG: clean_label=747 adv_label=747 distance=1.10\n",
      "n02093256.JPEG: clean_label=179 adv_label=179 distance=1.05\n",
      "n03109150.JPEG: clean_label=512 adv_label=512 distance=0.99\n",
      "n12267677.JPEG: clean_label=988 adv_label=988 distance=1.12\n",
      "n02667093.JPEG: clean_label=399 adv_label=399 distance=1.14\n",
      "n03956157.JPEG: clean_label=727 adv_label=727 distance=1.00\n",
      "n02033041.JPEG: clean_label=142 adv_label=142 distance=1.10\n",
      "n02071294.JPEG: clean_label=148 adv_label=148 distance=1.13\n",
      "n02704792.JPEG: clean_label=408 adv_label=408 distance=1.12\n",
      "n02013706.JPEG: clean_label=135 adv_label=135 distance=1.16\n",
      "n02177972.JPEG: clean_label=307 adv_label=307 distance=1.07\n",
      "n03042490.JPEG: clean_label=500 adv_label=500 distance=1.13\n",
      "n01443537.JPEG: clean_label=  1 adv_label=  1 distance=1.11\n",
      "n02093647.JPEG: clean_label=181 adv_label=296 distance=1.07\n",
      "n04536866.JPEG: clean_label=889 adv_label=889 distance=1.06\n",
      "n07717556.JPEG: clean_label=942 adv_label=942 distance=1.06\n",
      "n03016953.JPEG: clean_label=493 adv_label=493 distance=1.13\n",
      "n04493381.JPEG: clean_label=876 adv_label=876 distance=1.10\n",
      "n04590129.JPEG: clean_label=905 adv_label=905 distance=1.10\n",
      "n02769748.JPEG: clean_label=414 adv_label=414 distance=1.13\n",
      "n03063599.JPEG: clean_label=504 adv_label=504 distance=1.12\n",
      "n04065272.JPEG: clean_label=757 adv_label=757 distance=1.10\n",
      "n02012849.JPEG: clean_label=134 adv_label=134 distance=1.13\n",
      "n02655020.JPEG: clean_label=397 adv_label=397 distance=1.11\n",
      "n04548280.JPEG: clean_label=892 adv_label=905 distance=1.08\n",
      "n02129604.JPEG: clean_label=292 adv_label=292 distance=1.10\n",
      "n03393912.JPEG: clean_label=565 adv_label=565 distance=1.13\n",
      "n02110341.JPEG: clean_label=251 adv_label=251 distance=1.11\n",
      "n02791270.JPEG: clean_label=424 adv_label=691 distance=1.10\n",
      "n04251144.JPEG: clean_label=801 adv_label=801 distance=1.12\n",
      "n02443114.JPEG: clean_label=358 adv_label=358 distance=1.12\n",
      "n12144580.JPEG: clean_label=987 adv_label=987 distance=1.05\n",
      "n02966687.JPEG: clean_label=477 adv_label=477 distance=1.14\n",
      "n03584254.JPEG: clean_label=605 adv_label=605 distance=1.10\n",
      "n02110185.JPEG: clean_label=250 adv_label=250 distance=1.12\n",
      "n02790996.JPEG: clean_label=422 adv_label=422 distance=1.11\n",
      "n02815834.JPEG: clean_label=438 adv_label=438 distance=1.06\n",
      "n07831146.JPEG: clean_label=959 adv_label=959 distance=1.12\n",
      "n04311174.JPEG: clean_label=822 adv_label=822 distance=1.06\n",
      "n01955084.JPEG: clean_label=116 adv_label=116 distance=1.10\n",
      "n09332890.JPEG: clean_label=975 adv_label=975 distance=1.11\n",
      "n03197337.JPEG: clean_label=531 adv_label=531 distance=1.07\n",
      "n03467068.JPEG: clean_label=583 adv_label=583 distance=1.14\n",
      "n03201208.JPEG: clean_label=532 adv_label=532 distance=1.11\n",
      "n03485407.JPEG: clean_label=590 adv_label=590 distance=1.01\n",
      "n03873416.JPEG: clean_label=693 adv_label=693 distance=1.10\n",
      "n03131574.JPEG: clean_label=520 adv_label=520 distance=1.12\n",
      "n07754684.JPEG: clean_label=955 adv_label=955 distance=1.14\n",
      "n02086240.JPEG: clean_label=155 adv_label=154 distance=1.13\n",
      "n07836838.JPEG: clean_label=960 adv_label=960 distance=1.11\n",
      "n03160309.JPEG: clean_label=525 adv_label=525 distance=1.08\n",
      "n09399592.JPEG: clean_label=976 adv_label=976 distance=1.06\n",
      "n02777292.JPEG: clean_label=416 adv_label=416 distance=1.09\n",
      "n02326432.JPEG: clean_label=331 adv_label=331 distance=1.09\n",
      "n01664065.JPEG: clean_label= 33 adv_label= 33 distance=1.11\n",
      "n01537544.JPEG: clean_label= 14 adv_label= 14 distance=1.10\n",
      "n07583066.JPEG: clean_label=924 adv_label=924 distance=1.14\n",
      "n02814860.JPEG: clean_label=437 adv_label=437 distance=0.94\n",
      "n04153751.JPEG: clean_label=783 adv_label=783 distance=1.01\n",
      "n03379051.JPEG: clean_label=560 adv_label=560 distance=1.16\n",
      "n04597913.JPEG: clean_label=910 adv_label=910 distance=1.16\n",
      "n03977966.JPEG: clean_label=734 adv_label=734 distance=1.13\n",
      "n04606251.JPEG: clean_label=913 adv_label=913 distance=1.08\n",
      "n01773157.JPEG: clean_label= 72 adv_label= 72 distance=1.06\n",
      "n01688243.JPEG: clean_label= 43 adv_label= 43 distance=1.12\n",
      "n01829413.JPEG: clean_label= 93 adv_label= 93 distance=1.14\n",
      "n04525038.JPEG: clean_label=885 adv_label=885 distance=1.11\n",
      "n04049303.JPEG: clean_label=756 adv_label=756 distance=1.12\n",
      "n01877812.JPEG: clean_label=104 adv_label=104 distance=1.14\n",
      "n03394916.JPEG: clean_label=566 adv_label=566 distance=1.13\n",
      "n03794056.JPEG: clean_label=674 adv_label=674 distance=0.91\n",
      "n01530575.JPEG: clean_label= 10 adv_label= 10 distance=1.08\n",
      "n03207941.JPEG: clean_label=534 adv_label=534 distance=1.12\n",
      "n02109525.JPEG: clean_label=247 adv_label=247 distance=1.13\n",
      "n07697313.JPEG: clean_label=933 adv_label=933 distance=1.15\n",
      "n02489166.JPEG: clean_label=376 adv_label=376 distance=1.14\n",
      "n02794156.JPEG: clean_label=426 adv_label=426 distance=1.10\n",
      "n04131690.JPEG: clean_label=773 adv_label=711 distance=1.12\n",
      "\n",
      "Black-box attack successful rate: 8%\n"
     ]
    }
   ],
   "source": [
    "success_cnt = 0\n",
    "\n",
    "for idx, (imgname, label) in enumerate(images):\n",
    "    imgpath = './input_dir/' + imgname\n",
    "    run_list = [adv_image_t, distance_t, adv_label_black_t, saved_image_t]\n",
    "    feed_dict = {input_path: imgpath, input_label: label}\n",
    "    \n",
    "    adv_image, distance, adv_label, saved_image = sess.run(run_list, feed_dict)\n",
    "    adv_label = adv_label[0]\n",
    "    \n",
    "    # if the adversarial image can successfully fool the attacked model, and the perturbations are less than Max_Distance\n",
    "    if distance <= Max_Distance:\n",
    "        success_cnt += 1 if adv_label != label else 0\n",
    "    \n",
    "    print('{}: clean_label={:3d} adv_label={:3d} distance={:.2f}'.format(imgname,label,adv_label,distance))\n",
    "    \n",
    "    # save the generated images to './output_dir'\n",
    "    saved_image = tf.image.encode_png(saved_image)\n",
    "    write_ops = tf.io.write_file('./output_dir/' + imgname, saved_image)\n",
    "    sess.run(write_ops)\n",
    "\n",
    "print()\n",
    "print('Black-box attack successful rate: {}%'.format(success_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
